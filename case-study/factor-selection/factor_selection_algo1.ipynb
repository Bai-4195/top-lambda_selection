{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "941a48ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import itertools\n",
    "import random\n",
    "import time\n",
    "from concurrent.futures import ProcessPoolExecutor\n",
    "import sympy as sp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "35e7db71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate the model parameters\n",
    "class bayesian_network_posterior:\n",
    "    def __init__(self, the_R, tau2_R, kap_R, lam_R, mu, num_state, num_action, n_time, beta, v2):\n",
    "        self.the_R = the_R\n",
    "        self.tau2_R = tau2_R\n",
    "        self.kap_R = kap_R\n",
    "        self.lam_R = lam_R\n",
    "        self.num_nodes = (num_state + num_action) * n_time\n",
    "        self.num_state = num_state\n",
    "        self.num_action = num_action\n",
    "        self.mu = mu\n",
    "        self.beta = beta\n",
    "        self.v2 = v2\n",
    "        self.n_time = n_time\n",
    "\n",
    "    def posterior_sample(self, size=1, useFixed = True):\n",
    "        p_beta = np.zeros(shape=(self.num_nodes,self.num_nodes, size))\n",
    "        p_v2 = np.zeros(shape=(self.num_nodes, size))\n",
    "        for i in range(self.num_nodes):\n",
    "            for j in range(self.num_nodes):\n",
    "                if self.tau2_R[i, j] != 0:\n",
    "                    p_beta[i, j, ] = np.random.normal(loc=self.the_R[i,j], scale=np.sqrt(self.tau2_R[i,j]), size=size)\n",
    "            gamma_rate = self.lam_R[i] / 2\n",
    "            p_v2[i,] = 1 / np.random.gamma(shape=self.kap_R[i] / 2, scale=1/gamma_rate, size=size)\n",
    "        if useFixed:\n",
    "            p_beta = self.beta\n",
    "            p_v2 = self.v2\n",
    "        return (p_beta, p_v2, self.mu)\n",
    "\n",
    "class bayesian_network:\n",
    "    def __init__(self, mu, beta, v2, num_action, num_state, n_time, normalized = True, sample_mean=None, sample_sd=None):\n",
    "        self.n_time = n_time\n",
    "        if normalized:\n",
    "            self.sample_mean = sample_mean\n",
    "            self.sample_sd = sample_sd\n",
    "            self.normalized = True\n",
    "        self.initial_state_full = np.array([0.05, 0.00, 0.00, 30.00, 5.00,0.7])\n",
    "        if num_state == 4:\n",
    "            self.initial_state_base = self.initial_state_full[[0, 1, 3, 4, 5]]\n",
    "        if num_state == 5:\n",
    "            self.initial_state_base = self.initial_state_full\n",
    "        self.mu = mu\n",
    "        self.v2 = v2\n",
    "        self.beta = beta\n",
    "        self.num_action = num_action\n",
    "        self.num_state = num_state\n",
    "        self.n_factor = num_action + num_state\n",
    "        self.beta_state = np.zeros(shape=(n_time, num_state, num_state)) # s -> s\n",
    "        self.beta_action = np.zeros(shape=(n_time, num_action, num_state)) # a -> s\n",
    "        for i in range(n_time-1):\n",
    "            self.beta_state[i,:,:] = beta[(self.n_factor * (i+1) - num_state):(self.n_factor * (i+1)), (self.n_factor * (i + 2) - num_state): (self.n_factor * (i + 2))]\n",
    "            self.beta_action[i,:,:] = beta[(self.n_factor * i):(self.n_factor * i + self.num_action), (self.n_factor * (i + 2) - num_state):(self.n_factor * (i + 2))]\n",
    "        self.mu_a = []\n",
    "        for i in range(self.n_time):\n",
    "            temp_list = []\n",
    "            for j in range(self.num_action):\n",
    "                temp_list.append(self.mu[i * self.n_factor + j])\n",
    "            self.mu_a.append(temp_list)\n",
    "\n",
    "    def initial_state_generator(self, scale=10):\n",
    "        init_states = self.initial_state_base + np.abs(np.random.normal(0, np.array(self.initial_state_base)/scale + 0.01))\n",
    "        init_states = init_states[[0,1,3,4,5]] # init_states[:-1] * init_states[-1]\n",
    "        self.initial_state = (init_states - self.sample_mean[(self.n_factor - self.num_state):self.n_factor]) / self.sample_sd[(self.n_factor - self.num_state):self.n_factor]\n",
    "\n",
    "    def rescale_action(self, action, t, scale_method = \"standard\"):\n",
    "        if not self.normalized:\n",
    "            return action\n",
    "        if scale_method == \"standard\":\n",
    "            return self.sample_sd[(self.n_factor * t):(self.n_factor * t + self.num_action)] * action + self.sample_mean[(self.n_factor * t):(self.n_factor * t + self.num_action)]\n",
    "        else:\n",
    "            return self.sample_sd[(self.n_factor * t):(self.n_factor * t + self.num_action)] * action\n",
    "\n",
    "    def rescale_state(self, state, t, scale_method = \"standard\"):\n",
    "        if not self.normalized:\n",
    "            return state\n",
    "        if scale_method == \"standard\":\n",
    "            return self.sample_sd[(self.n_factor * (t+1) - self.num_state):(self.n_factor * (t+1))] * state + self.sample_mean[(self.n_factor * (t+1) - self.num_state):(self.n_factor * (t+1))]\n",
    "        else:\n",
    "            return self.sample_sd[(self.n_factor * (t+1) - self.num_state):(self.n_factor * (t+1))] * state\n",
    "        \n",
    "beta_gibbs = pd.read_csv('data/beta_s5a1-R15-explore0.3-v1-modelrisk--ntime36-sigma10.txt', header=None, dtype=np.float64)\n",
    "v2_gibbs = pd.read_csv('data/v2_s5a1-R15-explore0.3-v1-modelrisk--ntime36-sigma10.txt', header=None,\n",
    "                        dtype=np.float64)\n",
    "the_R = pd.read_csv('data/the_R_s5a1-R15-explore0.3-v1-modelrisk--ntime36-sigma10.txt', header=None, dtype=np.float64)\n",
    "tau2_R = pd.read_csv('data/tau2_R_s5a1-R15-explore0.3-v1-modelrisk--ntime36-sigma10.txt', header=None, dtype=np.float64)\n",
    "kap_R = pd.read_csv('data/kap_R_s5a1-R15-explore0.3-v1-modelrisk--ntime36-sigma10.txt', header=None, dtype=np.float64)\n",
    "lam_R = pd.read_csv('data/lam_R_s5a1-R15-explore0.3-v1-modelrisk--ntime36-sigma10.txt', header=None, dtype=np.float64)\n",
    "mu = pd.read_csv('data/mu_s5a1-R15-explore0.3-v1-modelrisk--ntime36-sigma10.txt', header=None, dtype=np.float64)\n",
    "sd = pd.read_csv('data/sd_s5a1-R15-explore0.3-v1-modelrisk--ntime36-sigma10.txt', header=None, dtype=np.float64)\n",
    "bn_post = bayesian_network_posterior(the_R.to_numpy(), tau2_R.to_numpy(), kap_R.to_numpy(), lam_R.to_numpy(),\n",
    "                                         mu.to_numpy().flatten(), 5, 1, 36, beta_gibbs, v2_gibbs)\n",
    "# mua = np.array(mu.to_numpy().reshape(36, 6)[:, 0]).reshape(1, 36)\n",
    "# mus = np.array(mu.to_numpy().reshape(36, 6)[:, 1:]).reshape(5, 36)\n",
    "\n",
    "# 这个函数可以生成5个状态和5个状态之间的协方差矩阵，随机生成相关性矩阵，代表了H=36个周期\n",
    "def simulate(H = 36, nums = 5, seed = 1):\n",
    "    np.random.seed(seed)\n",
    "    V_mat = np.zeros((H*nums, H*nums))\n",
    "    mat = (2*np.random.rand((H-1)*nums, (H-1)*nums)-1)/5\n",
    "    V_mat[nums*1:nums*H, nums*1:nums*H] = mat.dot(mat.T)\n",
    "    return V_mat\n",
    "\n",
    "def new_simulate(H = 36, nums = 5, seed = 1):\n",
    "    np.random.seed(seed)\n",
    "    V_mat = np.zeros((H*nums, H*nums))\n",
    "    mat = (2*np.random.rand(H*nums, H*nums)-1)/5\n",
    "    V_mat[nums*0:nums*H, nums*0:nums*H] = mat.dot(mat.T)\n",
    "    return V_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ff5e72b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1)\n",
    "nums = 5\n",
    "H = 3\n",
    "# 只需要生成一个样本，用来当作真实的参数\n",
    "ssize1 = 1\n",
    "#p_beta, p_v2, mu0 = bn_post.posterior_sample(ssize1, useFixed=False)\n",
    "#v_mat = simulate(H=H, seed = 4) # 这个可以得到一个随机的random factor的协方差矩阵,定义为多元正态分布，均值为0\n",
    "p_beta = np.load('p_beta.npy')\n",
    "p_v2 = np.load('p_v2.npy')\n",
    "mu0 = np.load('mu0.npy')\n",
    "v_mat = np.load('v_mat.npy')\n",
    "mu = pd.read_csv('data/mu_s5a1-R15-explore0.3-v1-modelrisk--ntime36-sigma10.txt', header=None, dtype=np.float64) \n",
    "s1 = np.array([0.05,0,30,5,0.7])\n",
    "theta = np.load('theta.npy')\n",
    "\n",
    "# b_r 和 c_r是组成奖励函数的参数\n",
    "b_r = np.repeat(-534.52, H)\n",
    "c_r = np.zeros((5, H))\n",
    "c_r[1, H-1] = 1.29\n",
    "\n",
    "\n",
    "beta = p_beta[:,:,0]\n",
    "v2 = p_v2[:,0]\n",
    "bn = bayesian_network(mu0, beta, v2, 1, 5, 36, True, mu, sd.to_numpy().flatten())\n",
    "# mu_a mu_s beta_a beta_s theta_0事先就可以确定下来，不需要在过程中计算\n",
    "mua = np.array(bn.mu_a).reshape(1, 36)\n",
    "mus = np.array(bn.mu.reshape(36, 6)[:,1:]).reshape(5,36)\n",
    "betas = np.zeros((5, 5, 36))\n",
    "for i in range(36):\n",
    "    betas[:,:,i] = bn.beta_state[i,:,:]\n",
    "betaa = np.transpose(bn.beta_action.reshape(36,5))\n",
    "\n",
    "# 为了减少维数，进行截断\n",
    "mua = mua[:,:H]\n",
    "mus = mus[:,:H]\n",
    "betas = betas[:,:,:H]\n",
    "betaa = betaa[:,:H]\n",
    "theta = theta[:,:H-1]\n",
    "\n",
    "theta_0 = np.concatenate((theta, np.zeros((nums, 1))), axis = 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "084557c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义一些基本的函数\n",
    "def reward(b_r, c_r, a, s):\n",
    "    return np.dot(b_r,a) + np.dot(c_r, s)\n",
    "\n",
    "def policy(mua, mus, theta, s):\n",
    "    return mua + np.dot(theta, s - mus)\n",
    "\n",
    "# 这里的转移函数暂时不考虑随机因子\n",
    "def transition(mus1, mus, mua, betas, betaa,s, a):\n",
    "    return mus1 + np.dot(betas, s - mus) + betaa*(a - mua)\n",
    "\n",
    "def get_elements_before(lst, element):\n",
    "    # 获取目标元素在列表中的索引\n",
    "    if element in lst:\n",
    "        index = lst.index(element)\n",
    "        # 返回索引之前的所有元素\n",
    "        return lst[:index]\n",
    "    else:\n",
    "        return []  # 如果目标元素不在列表中，返回空列表\n",
    "\n",
    "def factorial_iterative(n):\n",
    "    result = 1\n",
    "    for i in range(1, n + 1):\n",
    "        result *= i\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "96d28a24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 基于排列采样的shapley值的计算，首先是根据subset来采样随机因子\n",
    "def random_factor_generator(subset):\n",
    "    # 已知正态分布，根据subset中的随机因子采样\n",
    "    # 获得subset中对应的方差和协方差信息\n",
    "    global v_mat\n",
    "    cov = np.zeros((len(subset), len(subset)))\n",
    "    for i in range(len(subset)):\n",
    "        for j in range(len(subset)):\n",
    "            cov[i][j] = v_mat[subset[i]][subset[j]]\n",
    "    mean = np.zeros(cov.shape[0])  # 均值向量，0向量\n",
    "    sample = np.random.multivariate_normal(mean, cov, size=1)\n",
    "    return sample[0]\n",
    "\n",
    "def simulation_sample(subset, sample):\n",
    "    # 根据随机因子和对应的值，采样\n",
    "    global H, nums, v_mat\n",
    "    # 为了生成条件分布下的样本，先得到条件分布\n",
    "    rest_factor = [i for i in range(H*nums)]\n",
    "    for i in subset:\n",
    "        rest_factor.remove(i)\n",
    "    \n",
    "    x1 = sample\n",
    "    \n",
    "    sigma11 = np.zeros((len(subset), len(subset)))\n",
    "    sigma12 = np.zeros((len(subset), len(rest_factor)))\n",
    "    sigma22 = np.zeros((len(rest_factor), len(rest_factor)))\n",
    "    for i in range(len(subset)):\n",
    "        for j in range(len(subset)):\n",
    "            sigma11[i][j] = v_mat[subset[i]][subset[j]]\n",
    "    for i in range(len(subset)):\n",
    "        for j in range(len(rest_factor)):\n",
    "            sigma12[i][j] = v_mat[subset[i]][rest_factor[j]]\n",
    "    for i in range(len(rest_factor)):\n",
    "        for j in range(len(rest_factor)):\n",
    "            sigma22[i][j] = v_mat[rest_factor[i]][rest_factor[j]]\n",
    "    sigma21 = sigma12.T\n",
    "\n",
    "    inverse_sigma11 = sigma11\n",
    "\n",
    "    if np.linalg.det(sigma11) == 0: # 没有逆矩阵，使用伪逆\n",
    "        inverse_sigma11 = np.linalg.pinv(sigma11)\n",
    "    else:\n",
    "        inverse_sigma11 = np.linalg.inv(sigma11)\n",
    "    # 计算条件均值和条件协方差\n",
    "    condition_mean = np.dot(sigma21, inverse_sigma11).dot(x1)\n",
    "    condition_cov = sigma22 - np.dot(sigma21, inverse_sigma11).dot(sigma12)\n",
    "\n",
    "    # 从条件分布中生成剩余3个变量的样本\n",
    "    x2_sample = np.random.multivariate_normal(condition_mean, condition_cov, size = 1)\n",
    "    return x2_sample[0]\n",
    "\n",
    "def update_random_factor_sample(subset1,sample1, sample2):\n",
    "    # 这个函数用来还原出随机因子的采样值\n",
    "    global H, nums\n",
    "    subset2 = [i for i in range(H*nums)]\n",
    "    for i in subset1:\n",
    "        subset2.remove(i)\n",
    "    new_sample = np.zeros(H*nums)\n",
    "    new_sample[subset1] = sample1\n",
    "    new_sample[subset2] = sample2\n",
    "    return new_sample\n",
    "\n",
    "# 接下来是正式开始计算一次仿真的收益\n",
    "def nn_value_function(subset):\n",
    "    subset = sorted(subset)\n",
    "    # 这里面是排好序的子集\n",
    "    global H,nums,Nnn, v_mat\n",
    "    if len(subset) == 0:\n",
    "        res = 0\n",
    "        mean = np.zeros(H*nums)\n",
    "        for _ in range(Nnn):\n",
    "            x = np.random.multivariate_normal(mean, v_mat, size = 3)\n",
    "            y1 = PABN_simulation(x[0])\n",
    "            y2 = PABN_simulation(x[1])\n",
    "            y3 = PABN_simulation(x[2])\n",
    "            res += y1*(y2-y3)\n",
    "        return res/Nnn\n",
    "    if len(subset) == H*nums:\n",
    "        res = 0 \n",
    "        for _ in range(Nnn):\n",
    "            x0 = random_factor_generator(subset)\n",
    "            x1 = random_factor_generator(subset)\n",
    "            y1 = PABN_simulation(x0)\n",
    "            y2 = PABN_simulation(x0)\n",
    "            y3 = PABN_simulation(x1)\n",
    "            res += y1*(y2-y3)\n",
    "        return res/Nnn\n",
    "    res = 0\n",
    "    for _ in range(Nnn):\n",
    "        # 随机变量的两个采样值\n",
    "        xu0 = random_factor_generator(subset)\n",
    "        xu1 = random_factor_generator(subset)\n",
    "        xu0_rest1 = simulation_sample(subset, xu0)\n",
    "        x1 = update_random_factor_sample(subset, xu0, xu0_rest1)\n",
    "        xu0_rest2 = simulation_sample(subset, xu0)\n",
    "        x2 = update_random_factor_sample(subset, xu0, xu0_rest2)\n",
    "        xu1_rest = simulation_sample(subset, xu1)\n",
    "        x3 = update_random_factor_sample(subset, xu1, xu1_rest)\n",
    "        # 计算对应的reward\n",
    "        y1 = PABN_simulation(x1)\n",
    "        y2 = PABN_simulation(x2)\n",
    "        y3 = PABN_simulation(x3)\n",
    "        res += y1*(y2-y3)\n",
    "    return res/Nnn\n",
    "\n",
    "def PABN_simulation(random_factor):\n",
    "    global H,mua, mus, theta_0 ,betaa, betas, b_r, c_r, s1\n",
    "    cumulative_r = 0\n",
    "    state = np.zeros((nums, H))\n",
    "    state[:,0] = s1 + random_factor[0: nums]\n",
    "    a = np.zeros(H)\n",
    "    for t in range(H):\n",
    "        if t == 0:\n",
    "            state[:,t] = s1 + random_factor[0: nums]\n",
    "        else:\n",
    "            state[:,t] = transition(mus[:,t], mus[:,t-1], mua[:,t-1], betas[:,:,t-1], betaa[:,t-1], state[:,t-1], a[t-1]) + random_factor[t*nums: (t+1)*nums]\n",
    "        a[t] = policy(mua[:,t], mus[:,t], theta_0[:,t], state[:,t])\n",
    "        cumulative_r += reward(b_r[t], c_r[:,t], a[t], state[:,t])\n",
    "        \n",
    "    return cumulative_r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9e95ddd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def percent_choose(Sh_m, percent):\n",
    "    # Sort Sh_m in descending order and get the sorted indices\n",
    "    global H,nums\n",
    "    sorted_indices = np.argsort(Sh_m)[::-1]\n",
    "    sorted_values = np.sort(Sh_m)[::-1]\n",
    "    per = 0\n",
    "    Sh_choose = []\n",
    "    total_sum = np.sum(Sh_m)\n",
    "    for i in range(H*nums):\n",
    "        per += sorted_values[i]/total_sum\n",
    "        Sh_choose.append(sorted_indices[i])\n",
    "        if per >= percent:\n",
    "            break\n",
    "    return Sh_choose # 返回一个SV从大到小排序的索引\n",
    "\n",
    "def boundary_index(Sh_m, Sh_choose):\n",
    "    bound = len(Sh_choose)\n",
    "    i = np.argsort(Sh_m)[-bound]\n",
    "    j = np.argsort(Sh_m)[-(bound+1)]\n",
    "    return i,j\n",
    "\n",
    "def budget_allocation(N, incre, std, gap, num):\n",
    "    # 动态生成符号变量 pp\n",
    "    pp = sp.symbols(f'pp0:{num}')  # 使用动态参数 num 来生成符号变量列表\n",
    "    \n",
    "    under = (std / gap) ** 2\n",
    "    eq_sum = sp.Eq(sum(pp), np.sum(N) + incre)\n",
    "    eqs = [sp.Eq(pp[i] / under[i], pp[0] / under[0]) for i in range(1, num)]\n",
    "    solution = sp.solve([eq_sum] + eqs, pp)\n",
    "    N_star = np.zeros(H*nums)\n",
    "    for i in range(H*nums):\n",
    "        N_star[i] = np.floor(float(solution[pp[i]])) # 这里对浮点数的解向下取整\n",
    "    \n",
    "    # 多的就给最小的\n",
    "    while np.sum(N_star) < np.sum(N) + incre:\n",
    "        tmp = N_star / under\n",
    "        i = np.argmin(tmp)\n",
    "        N_star[i] += 1\n",
    "    \n",
    "    return N_star"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55414b9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 这个部分专门用来并行计算，用于计算重复的n次实验得到的结果\n",
    "s_time = time.time()\n",
    "Nnn = 1\n",
    "# 先用一个函数表示一次总的shapley计算，输入是重复的排列的个数\n",
    "def shapley_value(N):\n",
    "    global H,nums,Nnn\n",
    "    Sh_hat = np.zeros(H*nums)\n",
    "    N0 = 40000 # 试点仿真下给每个随机因子都分配的样本数, 计算夏普利值N0*H*nums次\n",
    "    #N = 100  总计算次数，二阶段分配次数 = N - N0*H*nums\n",
    "    Sh2 = np.zeros(H*nums)\n",
    "    N_set = np.zeros(H*nums)\n",
    "    gHL = np.zeros(H*nums)\n",
    "    z = -1.9599639845400545\n",
    "    alpha = 0.3\n",
    "    delta = 100000\n",
    "\n",
    "    for _ in range(N0):\n",
    "        perm = [i for i in range(H*nums)]\n",
    "        random.shuffle(perm)\n",
    "        for i in range(H*nums):\n",
    "            N_set[i] += 1\n",
    "            subset_before = get_elements_before(perm, i)\n",
    "            subset_include = subset_before + [i]\n",
    "            tmp = nn_value_function(subset_include) - nn_value_function(subset_before)\n",
    "            Sh_hat[i] += tmp\n",
    "            Sh2[i] += tmp**2 \n",
    "\n",
    "    while np.sum(N_set)< N:\n",
    "        Sh_mean = Sh_hat/N_set\n",
    "        sigma_hat = np.sqrt((Sh2 +np.square(Sh_hat)/N_set)/(N_set -1))\n",
    "        factor_choose = percent_choose(Sh_mean, lamb)\n",
    "        if len(factor_choose) < H*nums:\n",
    "            m, m1 = boundary_index(Sh_mean, factor_choose) # 取出相对应的索引\n",
    "            boundary = (sigma_hat[m1]*Sh_mean[m] + sigma_hat[m]*Sh_mean[m1])/(sigma_hat[m] + sigma_hat[m1])\n",
    "            gap = Sh_mean - boundary\n",
    "            N_star = budget_allocation(N_set, delta, sigma_hat, gap, H*nums)\n",
    "            incre_round = 0    \n",
    "            while incre_round < delta:\n",
    "                perm = [i for i in range(H*nums)]\n",
    "                random.shuffle(perm)\n",
    "                for i in range(H*nums):\n",
    "                    if incre_round < delta and N_set[i] < N_star[i]:\n",
    "                        incre_round += 1\n",
    "                        N_set[i] += 1\n",
    "                        subset_before = get_elements_before(perm, i)\n",
    "                        subset_include = subset_before + [i]\n",
    "                        tmp = nn_value_function(subset_include) - nn_value_function(subset_before)\n",
    "                        Sh_hat[i] = Sh_hat[i] + tmp\n",
    "                        Sh2[i] = Sh2[i] + tmp**2\n",
    "        else: # 所有随机因子都要选择，平均分配\n",
    "            times = int(delta/(H*nums))\n",
    "            for _ in range(times):\n",
    "                perm = [i for i in range(H*nums)]\n",
    "                random.shuffle(perm)\n",
    "                for i in range(H*nums):\n",
    "                    N_set[i] += 1\n",
    "                    subset_before = get_elements_before(perm, i)\n",
    "                    subset_include = subset_before + [i]\n",
    "                    tmp = nn_value_function(subset_include) - nn_value_function(subset_before)\n",
    "                    Sh_hat[i] += tmp\n",
    "                    Sh2[i] += tmp**2 \n",
    "\n",
    "    return Sh_hat/N_set\n",
    "\n",
    "inputs = [1500000 for i in range(64)] # 第一个数是N的大小，第二个数是cpu数\n",
    "\n",
    "with ProcessPoolExecutor(max_workers=64) as executor:\n",
    "# 使用partial将fixed_param绑定到shapley_value函数\n",
    "    results = list(executor.map(shapley_value, inputs))\n",
    "    \n",
    "e_time = time.time()\n",
    "print('算法总耗时：', e_time-s_time)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
